{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f790cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T08:50:40.970562Z",
     "start_time": "2025-04-28T08:50:40.874873Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from scipy import sparse, stats\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "SEED = 923984"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cda032b8a2214f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T08:44:47.876181Z",
     "start_time": "2025-04-25T14:34:18.297024Z"
    }
   },
   "outputs": [],
   "source": [
    "from reservoir.activation_functions import tanh, heaviside, sigmoid\n",
    "\n",
    "activation_function = lambda x : tanh(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb44384e-7cbc-4611-a015-e1c073f61aa9",
   "metadata": {},
   "source": [
    "# Loading and Preprocessing\n",
    "\n",
    "Lots of different on availabale : https://towardsdatascience.com/a-data-lakes-worth-of-audio-datasets-b45b88cd4ad\n",
    "\n",
    "Regression : http://tseregression.org/ + https://arxiv.org/pdf/2012.02974"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a8d6272-708d-4709-8e35-5a84268bed64",
   "metadata": {},
   "source": [
    "Prediction Datasets available :\n",
    "\n",
    "* MackeyGlass\n",
    "* Lorenz\n",
    "* Sunspot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94b219b-eb64-4715-b983-7de3c392f088",
   "metadata": {
    "collapsed": false,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    },
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "Classification Datasets available :\n",
    "\n",
    "* Custom :  FSDD, HAART, JapaneseVowels\n",
    "* Aeon : SpokenArabicDigits, CatsDogs, LSST\n",
    "* Torchaudio: SPEECHCOMMANDS\n",
    "\n",
    "More on https://www.timeseriesclassification.com/dataset.php or https://pytorch.org/audio/stable/datasets.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bec89b5c8a84dbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T14:34:23.492473Z",
     "start_time": "2025-04-25T14:34:20.660586Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#Preprocessing\n",
    "from datasets.multivariate_generation import generate_multivariate_dataset, extract_peak_frequencies\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from datasets.preprocessing import scale_data\n",
    "from datasets.preprocessing import add_noise, duplicate_data\n",
    "from datasets.load_data import load_data as load_dataset\n",
    "from sklearn.model_selection import StratifiedKFold, TimeSeriesSplit, StratifiedGroupKFold\n",
    "from datasets.preprocessing import flexible_indexing\n",
    "\n",
    "# Define noise parameter\n",
    "noise_std = 0.001\n",
    "\n",
    "data_type = \"normal\" # \"normal\" ou \"noisy\"\n",
    "\n",
    "def load_data(dataset_name, data_type, noise_std, step_ahead=5, visualize=False):\n",
    "    (is_instances_classification, is_multivariate, sampling_rate,\n",
    "     X_train_raw, X_test_raw, Y_train_raw, Y_test,\n",
    "     use_spectral_representation, spectral_representation,\n",
    "     groups) = load_dataset(dataset_name, step_ahead, visualize=False)\n",
    "    \n",
    "    WINDOW_LENGTH = 10\n",
    "    freq_train_data = X_train_raw\n",
    "    flat_train_data = np.concatenate(freq_train_data, axis=0) if is_instances_classification else freq_train_data\n",
    "    extract_peak_frequencies(flat_train_data, sampling_rate, smooth=True, window_length=WINDOW_LENGTH, threshold=1e-5, nperseg=1024, visualize=False)\n",
    "\n",
    "    if is_multivariate:\n",
    "        X_train_band, X_test_band = X_train_raw, X_test_raw\n",
    "        del X_train_raw, X_test_raw\n",
    "        X_val_band = None\n",
    "    else:\n",
    "        X_test, X_train = X_test_raw, X_train_raw\n",
    "        X_val, X_val_band = None, None\n",
    "        del X_train_raw, X_test_raw\n",
    "    Y_train = Y_train_raw\n",
    "    del Y_train_raw\n",
    "\n",
    "            \n",
    "    # PREPROCESSING\n",
    "    hop = 50 if is_instances_classification else 1\n",
    "    win_length = edge_cut = 100\n",
    "    if not is_multivariate:\n",
    "        X_train_band = generate_multivariate_dataset(\n",
    "            X_train, is_instances_classification, spectral_representation, hop=hop, win_length = win_length\n",
    "        )\n",
    "        \n",
    "        X_test_band = generate_multivariate_dataset(\n",
    "            X_test, is_instances_classification, spectral_representation, hop=hop, win_length = win_length\n",
    "        )\n",
    "    elif not use_spectral_representation:\n",
    "        X_train_band = generate_multivariate_dataset(\n",
    "            X_train_band, is_instances_classification, spectral_representation, hop=hop, win_length = win_length\n",
    "        )\n",
    "        X_test_band = generate_multivariate_dataset(\n",
    "            X_test_band, is_instances_classification, spectral_representation, hop=hop, win_length = win_length\n",
    "        )\n",
    "    else:\n",
    "        print(\"Data is already spectral and multivariate, nothing to do\")\n",
    "\n",
    "        \n",
    "    if not is_instances_classification:\n",
    "        X_train_band = X_train_band[edge_cut:-edge_cut] \n",
    "        X_test_band = X_test_band[edge_cut:-edge_cut] \n",
    "        \n",
    "        Y_train = Y_train[edge_cut:-edge_cut] \n",
    "        Y_test  = Y_test[edge_cut:-edge_cut]\n",
    "    \n",
    "    scaler_multi = MinMaxScaler(feature_range=(0, 1))\n",
    "    X_train_band, X_val_band, X_test_band = scale_data(X_train_band, X_val_band, X_test_band, scaler_multi, is_instances_classification)\n",
    "                \n",
    "    if not is_multivariate:\n",
    "        scaler_x_uni = MinMaxScaler(feature_range=(0, 1))\n",
    "        X_train, X_val, X_test = scale_data(X_train, X_val, X_test, scaler_multi, is_instances_classification)       \n",
    "    \n",
    "    # NOISE\n",
    "    if data_type == \"noisy\":\n",
    "        if is_instances_classification:\n",
    "            # UNI\n",
    "            if not is_multivariate:\n",
    "                X_train_noisy = [add_noise(instance, noise_std) for instance in tqdm(X_train, desc=\"TRAIN\")]\n",
    "                X_test_noisy = [add_noise(instance, noise_std) for instance in tqdm(X_test, desc=\"TEST\")]\n",
    "                \n",
    "            # MULTI\n",
    "            X_train_band_noisy = [add_noise(instance, noise_std) for instance in tqdm(X_train_band, desc=\"TRAIN\")]\n",
    "            X_test_band_noisy = [add_noise(instance, noise_std) for instance in tqdm(X_test_band, desc=\"TEST\")]\n",
    "        \n",
    "        else:  #if prediction\n",
    "            # UNI\n",
    "            if not is_multivariate:\n",
    "                X_train_noisy = add_noise(X_train, noise_std)\n",
    "                X_test_noisy = add_noise(X_test, noise_std)\n",
    "        \n",
    "            # MULTI\n",
    "            X_train_band_noisy = add_noise(X_train_band, noise_std)\n",
    "            X_test_band_noisy = add_noise(X_test_band, noise_std)\n",
    "    \n",
    "    # Define the number of instances you want to select\n",
    "    if is_instances_classification:\n",
    "        num_samples_for_pretrain = 500 if len(X_train_band) >= 500 else len(X_train_band)\n",
    "        indices = np.random.choice(len(X_train_band), num_samples_for_pretrain, replace=False)\n",
    "    else:\n",
    "        indices = range(len(X_train_band))\n",
    "    \n",
    "    \n",
    "    if data_type == \"noisy\":\n",
    "        # Defining pretrain   \n",
    "        if not is_multivariate:\n",
    "            X_pretrain_noisy = np.array(X_train_noisy, dtype=object)[indices].flatten()\n",
    "        X_pretrain_band_noisy = np.array(X_train_band_noisy, dtype=object)[indices]\n",
    "    \n",
    "    if not is_multivariate:\n",
    "        X_pretrain = np.array(X_train, dtype=object)[indices].flatten()\n",
    "    X_pretrain_band = np.array(X_train_band, dtype=object)[indices]\n",
    "\n",
    "    return X_pretrain_band, X_train_band, X_test_band, Y_train, Y_test, is_multivariate, is_instances_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048caacd-b461-4095-99bb-ebfbbc49cd3e",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Dataset characteristics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18ac2247-a66c-425d-a5e1-561398f350b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"CatsDogs\", \"FSDD\", \"JapaneseVowels\", \"SPEECHCOMMANDS\", \"SpokenArabicDigits\"\n",
    "]\n",
    "\n",
    "for dataset_name in datasets:\n",
    "    (is_instances_classification, is_multivariate, sampling_rate,\n",
    "     X_train_raw, X_test_raw, Y_train_raw, Y_test,\n",
    "     use_spectral_representation, spectral_representation,\n",
    "     groups) = load_dataset(dataset_name, 5, visualize=False)\n",
    "    \n",
    "    # Compute the length of each instance (assuming each instance is a 1D sequence)\n",
    "    lengths = [len(x) for x in X_train_raw]\n",
    "    avg_length = sum(lengths) / len(lengths)\n",
    "    \n",
    "    print(f\"Dataset: {dataset_name}  -->  Average length of X_train_raw: {avg_length:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1792b2bd-e48b-4acd-9a99-05e08ac699c3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the dataset list\n",
    "datasets = [\n",
    "    \"MackeyGlass\", \"Lorenz\", \"Sunspot_daily\", \"Henon\", \"NARMA\", \"CatsDogs\", \n",
    "    \"FSDD\", \"JapaneseVowels\", \"SPEECHCOMMANDS\", \"SpokenArabicDigits\"\n",
    "]\n",
    "\n",
    "# Function to test dataset characteristics\n",
    "def dataset_characteristics(dataset, data_type, noise_std):\n",
    "    pretrain_data, train_data, test_data, Y_train, Y_test, is_multivariate, is_instances_classification = load_data(dataset, data_type, noise_std, visualize=False)\n",
    "\n",
    "    # Score for prediction\n",
    "    if dataset == \"Sunspot\":\n",
    "        start_step = 30\n",
    "        end_step = 500\n",
    "    else:\n",
    "        start_step = 500\n",
    "        end_step = 1500\n",
    "    SLICE_RANGE = slice(start_step, end_step)\n",
    "\n",
    "    common_index = 1\n",
    "    if is_instances_classification:\n",
    "        common_size = pretrain_data[0].shape[common_index]\n",
    "    else:\n",
    "        common_size = pretrain_data.shape[common_index]\n",
    "\n",
    "    # We want the size of the reservoir to be at least network_size\n",
    "    network_size = 500\n",
    "    K = math.ceil(network_size / common_size)\n",
    "    n = common_size * K\n",
    "\n",
    "    # Pretraining dataset processing\n",
    "    if is_instances_classification:\n",
    "        unsupervised_pretrain = np.concatenate(pretrain_data).astype(float)\n",
    "    else:\n",
    "        unsupervised_pretrain = pretrain_data.astype(float)\n",
    "\n",
    "    # **Calculate total step count**\n",
    "    if is_instances_classification:\n",
    "        total_pretrain_length = sum(instance.shape[0] for instance in pretrain_data)\n",
    "        total_train_length = sum(instance.shape[0] for instance in train_data)\n",
    "        total_test_length = sum(instance.shape[0] for instance in test_data)\n",
    "        original_dimension = train_data[0].shape[1]\n",
    "        number_class = Y_test.shape[1]\n",
    "        \n",
    "        # Calculate min, max and average sample size over test+train datasets\n",
    "        sample_sizes = [instance.shape[0] for instance in train_data] + [instance.shape[0] for instance in test_data]\n",
    "        min_sample_size = min(sample_sizes)\n",
    "        max_sample_size = max(sample_sizes)\n",
    "        avg_sample_size = sum(sample_sizes) / len(sample_sizes)\n",
    "    else:\n",
    "        total_pretrain_length = pretrain_data.shape[0]\n",
    "        total_train_length = train_data.shape[0]\n",
    "        total_test_length = test_data.shape[0]\n",
    "        original_dimension = train_data.shape[1]\n",
    "        number_class = 0\n",
    "        min_sample_size = None\n",
    "        max_sample_size = None\n",
    "        avg_sample_size = None\n",
    "\n",
    "    return {\n",
    "        \"dataset_name\": dataset,\n",
    "        \"tot_pretrain_length\": total_pretrain_length,\n",
    "        \"tot_train_length\": total_train_length,\n",
    "        \"tot_test_length\": total_test_length,\n",
    "        \"origin_dim\": original_dimension,\n",
    "        \"nb_dupication\": K,\n",
    "        \"reservoir_size\": n,\n",
    "        \"final_dim\": common_size,\n",
    "        \"nb_class\": number_class,\n",
    "        \"min_sample_size\": min_sample_size,\n",
    "        \"max_sample_size\": max_sample_size,\n",
    "        \"avg_sample_size\": avg_sample_size,\n",
    "    }\n",
    "\n",
    "\n",
    "# Run tests on all datasets\n",
    "results = []\n",
    "for dataset in datasets:\n",
    "    characteristics = dataset_characteristics(dataset, data_type, noise_std)\n",
    "    results.append(characteristics)\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "# Save to CSV\n",
    "csv_filename = \"outputs/dataset_characteristics.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"Dataset characteristics saved to {csv_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e97986c1a958fc",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5606001921c4818e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T14:34:25.103549Z",
     "start_time": "2025-04-25T14:34:23.671726Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from numpy import random\n",
    "\n",
    "# Evaluating\n",
    "from performances.esn_model_evaluation import train_model_for_classification, predict_model_for_classification, compute_score\n",
    "from performances.esn_model_evaluation import (train_model_for_prediction, init_reservoir, init_ip_reservoir, init_local_rule_reservoir, \n",
    "                                                init_ip_local_rule_reservoir, init_readout)\n",
    "from analysis.richness import spectral_radius, pearson, squared_uncoupled_dynamics_alternative, distance_correlation\n",
    "from reservoir.reservoir import init_matrices\n",
    "from connexion_generation.hag import run_algorithm\n",
    "\n",
    "\n",
    "nb_jobs = 10\n",
    "def evaluate_dataset_on_test(study, dataset_name, function_name, pretrain_data, train_data, test_data, Y_train, Y_test, is_instances_classification, nb_trials = 8, record_metrics=False):\n",
    "    # Collect all hyperparameters in a dictionary\n",
    "    hyperparams = {param_name: param_value for param_name, param_value in study.best_trial.params.items()}\n",
    "    print(hyperparams)\n",
    "    leaky_rate = 1\n",
    "    input_connectivity = 1\n",
    "\n",
    "    # score for prediction\n",
    "    if dataset_name == \"Sunspot\":\n",
    "        start_step = 30\n",
    "        end_step = 500\n",
    "    else:\n",
    "        start_step = 500\n",
    "        end_step = 1500\n",
    "    SLICE_RANGE = slice(start_step, end_step)\n",
    "\n",
    "    if 'variance_target' not in hyperparams and 'min_variance' in hyperparams:\n",
    "        hyperparams['variance_target'] = hyperparams['min_variance']\n",
    "    if not is_instances_classification:\n",
    "        hyperparams['use_full_instance'] = False\n",
    "\n",
    "    RIDGE_COEF = 10**hyperparams['ridge']\n",
    "    \n",
    "    if function_name in [\"hadsp\", \"desp\"]:\n",
    "        max_partners = np.inf\n",
    "    \n",
    "    scores = [] \n",
    "    if record_metrics:\n",
    "        spectral_radii = []\n",
    "        pearson_correlations = []\n",
    "        CEVs = []\n",
    "        dcors = []\n",
    "    for i in range(nb_trials):\n",
    "        common_index = 1\n",
    "        if is_instances_classification:\n",
    "            common_size = pretrain_data[0].shape[common_index]\n",
    "        else:\n",
    "            common_size = pretrain_data.shape[common_index]\n",
    "\n",
    "        # We want the size of the reservoir to be at least network_size\n",
    "        K = math.ceil(hyperparams['network_size'] / common_size)\n",
    "        n = common_size * K\n",
    "        \n",
    "        if function_name in [\"diag_ee\", \"diag_ei\"]:\n",
    "            use_block = True\n",
    "        else:\n",
    "            use_block = False\n",
    "            \n",
    "        # UNSUPERVISED PRETRAINING \n",
    "        if function_name == \"random_ee\":\n",
    "            Win, W, bias = init_matrices(n, input_connectivity, hyperparams['connectivity'],  K, w_distribution=stats.uniform(loc=0, scale=1), use_block=use_block, seed=random.randint(0, 1000))\n",
    "        else:\n",
    "            Win, W, bias = init_matrices(n, input_connectivity, hyperparams['connectivity'],  K, w_distribution=stats.uniform(loc=-1, scale=2), use_block=use_block, seed=random.randint(0, 1000))\n",
    "        bias *= hyperparams['bias_scaling']\n",
    "        Win *= hyperparams['input_scaling']\n",
    "\n",
    "        if function_name == \"hadsp\":\n",
    "            W, (_, _, _) = run_algorithm(W, Win, bias, hyperparams['leaky_rate'], activation_function, pretrain_data, \n",
    "                                     hyperparams['weight_increment'], hyperparams['target_rate'], hyperparams['rate_spread'], function_name, \n",
    "                                     multiple_instances=is_instances_classification, \n",
    "                                     min_increment = hyperparams['min_increment'], max_increment=hyperparams['max_increment'], use_full_instance=hyperparams['use_full_instance'],\n",
    "                                     max_partners=max_partners, method=\"pearson\", n_jobs=nb_jobs)\n",
    "        elif function_name == \"desp\":\n",
    "            W, (_, _, _) = run_algorithm(W, Win, bias, hyperparams['leaky_rate'], activation_function, pretrain_data, \n",
    "                                         hyperparams['weight_increment'], hyperparams['variance_target'], hyperparams['variance_spread'], function_name, \n",
    "                                         multiple_instances=is_instances_classification, \n",
    "                                         min_increment = hyperparams['min_increment'], max_increment=hyperparams['max_increment'], use_full_instance = hyperparams['use_full_instance'], \n",
    "                                         max_partners=max_partners, method = \"pearson\", \n",
    "                                         intrinsic_saturation=hyperparams['intrinsic_saturation'], intrinsic_coef=hyperparams['intrinsic_coef'], \n",
    "                                         n_jobs = nb_jobs)\n",
    "        elif function_name in [\"random_ee\", \"random_ei\", \"diag_ee\", \"diag_ei\", \"ip_correct\", \"anti-oja_fast\", \"ip-anti-oja_fast\"]:\n",
    "            eigen = sparse.linalg.eigs(W, k=1, which=\"LM\", maxiter=W.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "            W *= hyperparams['spectral_radius'] / max(abs(eigen))\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid function: {function_name}\")\n",
    "        \n",
    "        # unsupervised local rules\n",
    "        if is_instances_classification:\n",
    "            unsupervised_pretrain = np.concatenate(pretrain_data).astype(float)\n",
    "        else:\n",
    "            unsupervised_pretrain = pretrain_data.astype(float)\n",
    "        if function_name == \"ip_correct\":\n",
    "            reservoir = init_ip_reservoir(W, Win, bias, mu=hyperparams['mu'], sigma=hyperparams['sigma'], learning_rate=hyperparams['learning_rate'],\n",
    "                                          leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function\n",
    "                                          )\n",
    "            _ = reservoir.fit(unsupervised_pretrain, warmup=100)\n",
    "        elif function_name == \"anti-oja_fast\":\n",
    "            reservoir = init_local_rule_reservoir(W, Win, bias, local_rule=\"anti-oja\", eta=hyperparams['oja_eta'],\n",
    "                                                  synapse_normalization=False, bcm_theta=None,\n",
    "                                                  leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function,\n",
    "                                                  )\n",
    "            _ = reservoir.fit(unsupervised_pretrain, warmup=100)        \n",
    "        elif function_name == \"ip-anti-oja_fast\":\n",
    "            reservoir = init_ip_local_rule_reservoir(W, Win, bias, local_rule=\"anti-oja\", eta=hyperparams['oja_eta'],\n",
    "                                                      synapse_normalization=False, bcm_theta=None,\n",
    "                                                      mu=hyperparams['mu'], sigma=hyperparams['sigma'], learning_rate=hyperparams['learning_rate'],\n",
    "                                                      leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function,\n",
    "                                                      )\n",
    "            _ = reservoir.fit(unsupervised_pretrain, warmup=100)\n",
    "        else:\n",
    "            reservoir = init_reservoir(W, Win, bias, leaky_rate, activation_function)\n",
    "        readout = init_readout(ridge_coef=RIDGE_COEF)\n",
    "\n",
    "        \n",
    "        # TRAINING and EVALUATION\n",
    "        if record_metrics:\n",
    "            inputs = np.concatenate(test_data, axis=0) if is_instances_classification else test_data\n",
    "            states_history_multi = reservoir.run(inputs)\n",
    "            \n",
    "            sr = spectral_radius(W)\n",
    "            pearson_correlation, _ = pearson(states_history_multi, num_windows=1, size_window=len(states_history_multi), step_size = 1, show_progress=False)\n",
    "            CEV = squared_uncoupled_dynamics_alternative(states_history_multi, num_windows=1, size_window=len(states_history_multi), step_size = 1, show_progress=True)\n",
    "            dcor = distance_correlation(states_history_multi, num_windows=1, size_window=len(states_history_multi), step_size = 1, show_progress=True, method=\"auto\", nb_jobs=nb_jobs)\n",
    "\n",
    "            spectral_radii.append(sr)\n",
    "            pearson_correlations.append(pearson_correlation[0])\n",
    "            CEVs.append(CEV[0])\n",
    "            dcors.append(dcor[0])\n",
    "        else:\n",
    "            if is_instances_classification:\n",
    "                mode = \"sequence-to-vector\"\n",
    "                train_model_for_classification(reservoir, readout, train_data, Y_train, n_jobs = nb_jobs, mode=mode)\n",
    "    \n",
    "                Y_pred = predict_model_for_classification(reservoir, readout, test_data, n_jobs = nb_jobs, mode=mode)\n",
    "                score = compute_score(Y_pred, Y_test, is_instances_classification)\n",
    "            else:\n",
    "                esn = train_model_for_prediction(reservoir, readout, train_data, Y_train, warmup=start_step, n_jobs = nb_jobs)\n",
    "                \n",
    "                Y_pred =  esn.run(test_data, reset=False)\n",
    "                score = compute_score(Y_pred[SLICE_RANGE], Y_test[SLICE_RANGE], is_instances_classification)\n",
    "    \n",
    "            scores.append(score)\n",
    "            \n",
    "    if record_metrics:\n",
    "        return spectral_radii, pearson_correlations, CEVs, dcors\n",
    "\n",
    "    return scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9049fbb3-7c63-4ed1-b969-cd5b4a00bef6",
   "metadata": {},
   "source": [
    "# Common visualisation definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59ae41a-4c2c-4d17-adcf-a812bdd9d42b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T14:34:27.903270Z",
     "start_time": "2025-04-25T14:34:27.896575Z"
    }
   },
   "outputs": [],
   "source": [
    "from seaborn import color_palette\n",
    "\n",
    "# -- Define color palettes for each group --\n",
    "blues = color_palette(\"Blues\", 5)      # shades of blue\n",
    "oranges = color_palette(\"Oranges\", 2)  # shades of orange\n",
    "greens = color_palette(\"Greens\", 2)    # shades of green\n",
    "reds = color_palette(\"Reds\", 2)    # shades of yellow\n",
    "\n",
    "# -- Map each function to its color --\n",
    "function_colors = {\n",
    "    'E-ESN':                greens[0],\n",
    "    'ESN':                  greens[1],\n",
    "    'IP':                   blues[0],\n",
    "    'Anti-Oja':             blues[1],\n",
    "    'Anti-Oja-Fast':        blues[2],\n",
    "    'IP +\\nAnti-Oja':       blues[3],\n",
    "    'IP +\\nAnti-Oja\\nFast': blues[4],\n",
    "    'mean HAG':             oranges[0],\n",
    "    'variance HAG':         oranges[1],\n",
    "#    'diag EE':             reds[0],\n",
    "#    'diag EI':             reds[1],\n",
    "}\n",
    "\n",
    "# If you want a specific order for the bars, you can enforce it:\n",
    "functions_order = [\n",
    "    'E-ESN',\n",
    "    'ESN',\n",
    "    'IP',\n",
    "    'Anti-Oja',\n",
    "    'IP +\\nAnti-Oja',\n",
    "    'mean HAG',\n",
    "    'variance HAG',\n",
    "#    'diag EE',\n",
    "#    'diag EI',\n",
    "]\n",
    "\n",
    "function_mapping = {\n",
    "    'ip-anti-oja_fast': 'IP +\\nAnti-Oja',\n",
    "    'ip_correct':       'IP',\n",
    "    'anti-oja_fast':    'Anti-Oja',\n",
    "    'desp':             'variance HAG',\n",
    "    'hadsp':            'mean HAG',\n",
    "    'random_ei':        'ESN',\n",
    "    'random_ee':        'E-ESN',\n",
    "#    'diag_ei':        'diag EI',\n",
    "#    'diag_ee':        'diag EE',\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "934bb5ed-a01e-4874-8b28-a9d7abde179d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# HPO Comparaison"
   ]
  },
  {
   "cell_type": "raw",
   "id": "977ffefd-1fc2-473c-a960-3f2f8c626f0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-02-26T22:54:20.816445Z",
     "iopub.status.busy": "2025-02-26T22:54:20.816130Z",
     "iopub.status.idle": "2025-02-26T23:05:00.885803Z",
     "shell.execute_reply": "2025-02-26T23:05:00.884567Z",
     "shell.execute_reply.started": "2025-02-26T22:54:20.816422Z"
    },
    "scrolled": true
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "from performances.utility import camel_to_snake, retrieve_best_model\n",
    "\n",
    "# Your existing imports\n",
    "# from performances.utility import retrieve_best_model  # Now replaced with new retrieve_best_model above\n",
    "\n",
    "# Add \"Sampler\" to the columns\n",
    "columns = ['Dataset', 'Function', 'Sampler', 'Average Score', 'Standard Deviation', 'Date']\n",
    "variate_type = \"multi\"  # \"multi\" or \"uni\"\n",
    "file_name = \"outputs/hpo_strategy.csv\"\n",
    "\n",
    "for dataset_name in [\"JapaneseVowels\"]: \n",
    "    new_results = pd.DataFrame(columns=columns)\n",
    "    pretrain_data, train_data, test_data, Y_train, Y_test, is_multivariate, is_instances_classification = load_data(dataset_name, data_type, noise_std, visualize=True)\n",
    "\n",
    "\n",
    "    \n",
    "    print(f\"===== DATASET: {dataset_name} =====\")\n",
    "    \n",
    "    for sampler_name in [\"cmaes\", \"tpe\"]:\n",
    "        print(f\"--- Sampler: {sampler_name} ---\")\n",
    "        for function_name in [\"desp\", \"hadsp\", \"ip-anti-oja\", \"anti-oja\", \"ip_correct\", \"random_ee\", \"random_ei\"]:\n",
    "            print(\"Function:\", function_name)\n",
    "\n",
    "            # Retrieve the best study for that (sampler, function, dataset)\n",
    "            study = retrieve_best_model(\n",
    "                function_name=function_name,\n",
    "                dataset_name=dataset_name,\n",
    "                is_multivariate=is_multivariate,\n",
    "                variate_type=variate_type,\n",
    "                data_type=\"normal\",           # or \"noisy\" if needed\n",
    "                sampler_name=sampler_name\n",
    "            )\n",
    "\n",
    "            # Evaluate on test set\n",
    "            scores = evaluate_dataset_on_test(\n",
    "                study,\n",
    "                dataset_name,\n",
    "                function_name,\n",
    "                pretrain_data,\n",
    "                train_data,\n",
    "                test_data,\n",
    "                Y_train,\n",
    "                Y_test,\n",
    "                is_instances_classification,\n",
    "                record_metrics=False\n",
    "            )\n",
    "\n",
    "            average_score = np.mean(scores)\n",
    "            std_deviation = np.std(scores)\n",
    "\n",
    "            if is_instances_classification:\n",
    "                # Classification => format as percent\n",
    "                formatted_average = f\"{round(average_score * 100, 5)} %\"\n",
    "                formatted_std = f\"± {round(std_deviation * 100, 5)} %\"\n",
    "            else:\n",
    "                # Prediction => raw numeric\n",
    "                formatted_average = f\"{round(average_score, 5)}\"\n",
    "                formatted_std = f\"± {round(std_deviation, 5)}\"\n",
    "            \n",
    "            current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "\n",
    "            # Add to this dataset's results\n",
    "            new_row = pd.DataFrame({\n",
    "                'Dataset': [dataset_name],\n",
    "                'Function': [function_name],\n",
    "                'Sampler': [sampler_name],\n",
    "                'Average Score': [formatted_average],\n",
    "                'Standard Deviation': [formatted_std],\n",
    "                'Date': [current_date]\n",
    "            })\n",
    "            new_results = pd.concat([new_results, new_row], ignore_index=True)\n",
    "\n",
    "    # Show results for this dataset\n",
    "    print(\"\\n== New results for\", dataset_name, \"==\")\n",
    "    print(new_results)\n",
    "    \n",
    "    # Load or create local CSV file\n",
    "    if os.path.exists(file_name):\n",
    "        previous_results = pd.read_csv(file_name)\n",
    "    else:\n",
    "        columns = ['Dataset', 'Function', 'Sampler', 'Average Score', 'Standard Deviation', 'Date']\n",
    "        previous_results = pd.DataFrame(columns=columns)\n",
    "        previous_results.to_csv(file_name, index=False)\n",
    "        print(f\"{file_name} created successfully.\")\n",
    "        \n",
    "    # Combine new + old\n",
    "    tots_results = pd.concat([new_results, previous_results], axis=0)\n",
    "\n",
    "    # Save\n",
    "    tots_results.to_csv(file_name, index=False)\n",
    "    print(f\"Results saved to {file_name}.\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecaa6e8c-b933-4f0c-8ea5-9c553217abff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read your CSV file (already containing TPE vs. CMA-ES results)\n",
    "file_name = \"outputs/hpo_strategy.csv\"\n",
    "df = pd.read_csv(file_name)\n",
    "\n",
    "# --- 1) Basic Cleanup ---\n",
    "# Remove '%' from \"Average Score\" so we can convert to float\n",
    "df['Average Score'] = pd.to_numeric(\n",
    "    df['Average Score'].str.replace('%', ''), \n",
    "    errors='coerce'\n",
    ")\n",
    "# Remove '±' and '%' from \"Standard Deviation\"\n",
    "df['Standard Deviation'] = pd.to_numeric(\n",
    "    df['Standard Deviation'].str.replace('±', '').str.replace('%', ''), \n",
    "    errors='coerce'\n",
    ")\n",
    "\n",
    "\n",
    "# Optionally remove an unwanted function\n",
    "# df = df[df['Function'] != 'ip']\n",
    "\n",
    "# Rename functions for your final labels\n",
    "df['Function'] = df['Function'].replace(function_mapping)\n",
    "\n",
    "# Optional replacements for dataset names\n",
    "df['Dataset'] = df['Dataset'].replace({\n",
    "    'JapaneseVowels':     'Japanese\\nVowels',\n",
    "})\n",
    "\n",
    "\n",
    "# 2b) distinguish TPE vs CMA-ES by hatch pattern (or alpha, edgecolor, etc.)\n",
    "sampler_hatching = {\n",
    "    'tpe':   '',     # no hatch\n",
    "    'cmaes': '///',  # diagonal hatch\n",
    "}\n",
    "\n",
    "# Filter to only those in the DataFrame\n",
    "functions = [f for f in functions_order if f in df['Function'].unique()]\n",
    "\n",
    "# If you also want an explicit order for Sampler\n",
    "samplers = ['tpe', 'cmaes']\n",
    "\n",
    "# --- 3) Build the grouped bar chart ---\n",
    "\n",
    "datasets = df['Dataset'].unique()\n",
    "datasets.sort()  # optional: sort datasets alphabetically\n",
    "x = np.arange(len(datasets))  # label locations\n",
    "width = 0.08                  # narrower bar for more sub-bars\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "fontsize = 12\n",
    "\n",
    "# Outer loop over functions\n",
    "for i, func in enumerate(functions):\n",
    "    # Inner loop over the two samplers\n",
    "    for j, sampler in enumerate(samplers):\n",
    "        # Horizontal offset for each bar\n",
    "        # We have 2 samplers per function, so total sub-width = 2*width\n",
    "        offset = i * (2 * width) + j * width\n",
    "\n",
    "        # Extract rows for this function + sampler\n",
    "        sub_df = df[(df['Function'] == func) & (df['Sampler'] == sampler)]\n",
    "\n",
    "        # Merge with the dataset ordering to align bar positions\n",
    "        merged = pd.DataFrame({'Dataset': datasets}).merge(sub_df, on='Dataset', how='left')\n",
    "\n",
    "        # Plot the bars\n",
    "        ax.bar(\n",
    "            x + offset,\n",
    "            merged['Average Score'],\n",
    "            width,\n",
    "            label=None,  # We'll manually handle legend\n",
    "            yerr=merged['Standard Deviation'],\n",
    "            capsize=4,\n",
    "            color=function_colors.get(func, 'gray'),  # fallback color if missing\n",
    "            hatch=sampler_hatching.get(sampler, ''),  # or '' if missing\n",
    "            edgecolor='black'                         # optional to see the hatch better\n",
    "        )\n",
    "\n",
    "# --- 4) Cosmetic adjustments ---\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.tick_params(axis='both', labelsize=fontsize)\n",
    "\n",
    "# X-axis label\n",
    "ax.set_xlabel('Dataset', fontsize=fontsize)\n",
    "\n",
    "# Y-axis label (change if classification vs. NRMSE)\n",
    "# e.g., if your CSV is for classification, you might put \"Classification Rate (%)\"\n",
    "ax.set_ylabel('Average Score', fontsize=fontsize)\n",
    "\n",
    "# Position x-ticks in the center of each dataset group\n",
    "total_functions = len(functions)\n",
    "total_samplers = len(samplers)  # 2\n",
    "group_width = total_functions * total_samplers * width\n",
    "ax.set_xticks(x + group_width/2 - (width/2))\n",
    "ax.set_xticklabels(datasets, rotation=0)\n",
    "\n",
    "# --- 5) Build a custom legend ---\n",
    "# 5a) Legend for the Functions (colors)\n",
    "from matplotlib.patches import Patch\n",
    "\n",
    "function_legend = [\n",
    "    Patch(facecolor=function_colors[f], edgecolor='black', label=f) for f in functions\n",
    "]\n",
    "\n",
    "# 5b) Legend for the Samplers (hatching)\n",
    "sampler_legend = [\n",
    "    Patch(facecolor='white', edgecolor='black', hatch=sampler_hatching[s], \n",
    "          label=s.upper())  # or s.title()\n",
    "    for s in samplers\n",
    "]\n",
    "\n",
    "# Combine them in one line, or do them separately\n",
    "first_legend = ax.legend(handles=function_legend, title='Function', loc='upper left', fontsize=fontsize)\n",
    "ax.add_artist(first_legend)  # explicitly add the first legend, then a second one\n",
    "ax.legend(handles=sampler_legend, title='Sampler', loc='lower left', fontsize=fontsize)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61a2af988df0f5e",
   "metadata": {},
   "source": [
    "# Test scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "453e899e0651f36b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from performances.utility import retrieve_best_model\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "columns = ['Dataset', 'Function', 'Average Score', 'Standard Deviation', 'Date']\n",
    "variate_type = \"multi\"  # \"multi\" or \"uni\"\n",
    "\n",
    "for dataset_name in [\"SPEECHCOMMANDS\"]:\n",
    "    new_results = pd.DataFrame(columns=columns)\n",
    "    # Can be \"MackeyGlass\", \"Lorenz\", \"Sunspot_daily\", \"CatsDogs\", \"JapaneseVowels\", \"SpokenArabicDigits\", \"FSDD\", \"SPEECHCOMMANDS\"\n",
    "    pretrain_data, train_data, test_data, Y_train, Y_test, is_multivariate, is_instances_classification = load_data(dataset_name, data_type, noise_std, visualize=True)\n",
    "    if is_instances_classification:\n",
    "        file_name = \"test_results/test_results_classification.csv\"\n",
    "    else: \n",
    "        file_name = \"test_results/test_results_prediction.csv\"\n",
    "    print(dataset_name)\n",
    "    # Simulate your data and loop for evaluation\n",
    "    \n",
    "    # \"random_ee\", \"random_ei\", \"diag_ee\", \"diag_ei\", \"ip_correct\", \"anti-oja_fast\",  \"ip-anti-oja_fast\", \"hadsp\", \"desp\"\n",
    "    for function_name in [\"ip_correct\", \"hadsp\", \"desp\"]:\n",
    "        print(function_name)\n",
    "        study = retrieve_best_model(function_name, dataset_name, is_multivariate, variate_type = \"multi\", data_type = \"normal\")\n",
    "    \n",
    "        scores = evaluate_dataset_on_test(\n",
    "            study, \n",
    "            dataset_name,\n",
    "            function_name, \n",
    "            pretrain_data, \n",
    "            train_data, \n",
    "            test_data,\n",
    "            Y_train, \n",
    "            Y_test,\n",
    "            is_instances_classification,\n",
    "            nb_trials = 8,\n",
    "            record_metrics=False\n",
    "        )\n",
    "        # Compute the average and standard deviation of the scores\n",
    "        average_score = np.mean(scores)\n",
    "        std_deviation = np.std(scores)\n",
    "    \n",
    "        if is_instances_classification:\n",
    "            formatted_average = f\"{round(average_score * 100, 5)} %\"\n",
    "            formatted_std = f\"± {round(std_deviation * 100, 5)} %\"\n",
    "        else:\n",
    "            formatted_average = f\"{round(average_score, 5)}\"\n",
    "            formatted_std = f\"± {round(std_deviation, 5)}\"\n",
    "        \n",
    "        # Capture the current date\n",
    "        current_date = datetime.now().strftime('%Y-%m-%d')\n",
    "        \n",
    "        # Create a new DataFrame row with the Date column\n",
    "        new_row = pd.DataFrame({\n",
    "            'Dataset': [dataset_name],\n",
    "            'Function': [function_name],\n",
    "            'Average Score': [formatted_average],\n",
    "            'Standard Deviation': [formatted_std],\n",
    "            'Date': [current_date]\n",
    "        })\n",
    "        \n",
    "        # Concatenate the new row to the results DataFrame\n",
    "        new_results = pd.concat([new_results, new_row], ignore_index=True)\n",
    "    \n",
    "    \n",
    "    # Display the DataFrame\n",
    "    print(new_results)\n",
    "    \n",
    "    # Load the existing CSV\n",
    "    if os.path.exists(file_name):\n",
    "        previous_results = pd.read_csv(file_name)\n",
    "    else:\n",
    "        columns = ['Dataset', 'Function', 'Average Score', 'Standard Deviation', 'Date']\n",
    "        previous_results = pd.DataFrame(columns=columns)\n",
    "        previous_results.to_csv(file_name, index=False)\n",
    "        print(f\"{file_name} created successfully.\")\n",
    "        \n",
    "    tots_results = pd.concat([new_results, previous_results], axis=0)\n",
    "    \n",
    "    tots_results.to_csv(file_name, index=False)\n",
    "    print(f\"Results saved to {file_name}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e50beaff27b87",
   "metadata": {},
   "source": [
    "## Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc86944f1a29e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd \n",
    "\n",
    "file_name = \"test_results/test_results_classification.csv\"\n",
    "\n",
    "if 'file_name' not in locals() and 'file_name' not in globals():\n",
    "    file_name = \"test_results/test_results_prediction.csv\"  #  test_results_classification.csv or test_results_prediction.csv\n",
    "\n",
    "if os.path.exists(file_name):\n",
    "    previous_results = pd.read_csv(file_name)\n",
    "else:\n",
    "    # File does not exist, create it with the necessary columns\n",
    "    columns = ['Dataset', 'Function', 'Average Score', 'Standard Deviation', 'Date']\n",
    "    previous_results = pd.DataFrame(columns=columns)\n",
    "    # Save the empty DataFrame as a CSV\n",
    "    previous_results.to_csv(file_name, index=False)\n",
    "    print(f\"{file_name} created successfully.\")\n",
    "\n",
    "print(f\"Results saved to {file_name}.\")\n",
    "previous_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f301fa1838a4b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "all_results = pd.read_csv(file_name)\n",
    "df = pd.DataFrame(all_results)\n",
    "\n",
    "# Clean data as before\n",
    "df['Average Score'] = df['Average Score'].astype(str).str.replace('%', '').astype(float)\n",
    "df['Standard Deviation'] = df['Standard Deviation'].str.replace('±', '').str.replace('%', '').astype(float)\n",
    "\n",
    "df = df[df['Function'] != 'ip']\n",
    "\n",
    "df['Function'] = df['Function'].map(function_mapping)\n",
    "\n",
    "# Optional replacements for dataset names\n",
    "#df = df[df['Dataset'].isin([\"Lorenz\", \"MackeyGlass\", \"Sunspot\"])]\n",
    "\n",
    "if file_name == \"test_results/test_results_classification.csv\":\n",
    "    df['Dataset'] = df['Dataset'].str.replace('SpokenArabicDigits', 'Spoken\\nArabic\\nDigits')\n",
    "    df['Dataset'] = df['Dataset'].str.replace('SPEECHCOMMANDS', 'SPEECH\\nCOMMANDS')\n",
    "    df['Dataset'] = df['Dataset'].str.replace('JapaneseVowels', 'Japanese\\nVowels')\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "datasets = df['Dataset'].unique()\n",
    "x = np.arange(len(datasets))  # The label locations\n",
    "width = 0.1                   # Width of each bar\n",
    "\n",
    "for i, func in enumerate(functions_order):\n",
    "    # Grab only rows for this function\n",
    "    values = df[df['Function'] == func]\n",
    "    \n",
    "    # We create a Series in the same order as 'datasets'\n",
    "    merged = pd.DataFrame({'Dataset': datasets}).merge(values, on='Dataset', how='left')\n",
    "    \n",
    "    ax.bar(\n",
    "        x + i * width,\n",
    "        merged['Average Score'],\n",
    "        width,\n",
    "        label=func,\n",
    "        yerr=merged['Standard Deviation'],\n",
    "        capsize=5,\n",
    "        color=function_colors[func]\n",
    "    )\n",
    "\n",
    "fontsize = 14\n",
    "\n",
    "ax.spines['top'].set_visible(False)\n",
    "ax.spines['right'].set_visible(False)\n",
    "ax.tick_params(axis='both', labelsize=fontsize)\n",
    "\n",
    "if file_name == \"test_results/test_results_prediction.csv\":\n",
    "    plt.ylabel('NRMSE', size=fontsize)\n",
    "else:\n",
    "    plt.ylabel('Classification Rate', size=fontsize)\n",
    "plt.legend(title='Algorithm', fontsize=10, title_fontsize=fontsize, bbox_to_anchor=(0.5, 1.15), loc='upper center', ncol=len(functions_order))\n",
    "\n",
    "# Position x-ticks in the center of all the bars for each dataset\n",
    "ax.set_xticks(x + width * (len(functions_order)-1)/2)\n",
    "ax.set_xticklabels(datasets)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ae919b11422d98a",
   "metadata": {},
   "source": [
    "# Export best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b8311b29a31c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from performances.utility import camel_to_snake, retrieve_best_model\n",
    "\n",
    "\n",
    "# List of datasets (extract from filenames)\n",
    "datasets = [\n",
    "    \"SpokenArabicDigits\",\n",
    "    \"JapaneseVowels\",\n",
    "    \"FSDD\",\n",
    "    \"SPEECHCOMMANDS\",\n",
    "    \"CatsDogs\",\n",
    "    \"MackeyGlass\",\n",
    "    \"Lorenz\",\n",
    "    \"Sunspot_daily\",\n",
    "]\n",
    "\n",
    "for function_name in [\"random_ee\", \"random_ei\", \"ip_correct\", \"anti-oja_fast\",  \"ip-anti-oja_fast\", \"hadsp\", \"desp\"]:\n",
    "    results = []\n",
    "    for dataset in datasets:\n",
    "        study = retrieve_best_model(function_name, dataset, is_multivariate=True, variate_type = \"multi\", data_type = \"normal\")\n",
    "        best_trial = study.best_trial\n",
    "        results.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"function_name\": function_name,\n",
    "            **best_trial.params,\n",
    "        })\n",
    "    # Convert results to a DataFrame\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save to CSV\n",
    "    df.to_csv(f\"outputs/best_hyperparameters_{function_name}.csv\", index=False)\n",
    "    \n",
    "    print(f\"Results saved to best_hyperparameters_{function_name}.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7cec6b61c1fecd",
   "metadata": {},
   "source": [
    "# Richness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2661626e2cfc509c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import optuna\n",
    "import pandas as pd\n",
    "from performances.utility import camel_to_snake, retrieve_best_model\n",
    "\n",
    "# Create an empty DataFrame to store the results\n",
    "columns = [\n",
    "    \"dataset\", \n",
    "    \"function_name\", \n",
    "    \"spectral_radius_mean\", \n",
    "    \"spectral_radius_std\", \n",
    "    \"pearson_mean\", \n",
    "    \"pearson_std\",\n",
    "    \"CEV_mean\",\n",
    "    \"CEV_std\",\n",
    "    \"dcor_mean\",\n",
    "    \"dcor_std\",\n",
    "    \"final_correlations_mean\",\n",
    "    \"final_correlations_std\",\n",
    "]\n",
    "\n",
    "\n",
    "# List of datasets (extract from filenames)\n",
    "datasets = [\n",
    "#    \"JapaneseVowels\",\n",
    "#    \"CatsDogs\",\n",
    "#    \"FSDD\",\n",
    "#   \"SpokenArabicDigits\",\n",
    "    \"SPEECHCOMMANDS\",\n",
    "#    \"MackeyGlass\",\n",
    "#    \"Lorenz\",\n",
    "#    \"Sunspot_daily\",\n",
    "]\n",
    "\n",
    "\n",
    "new_results = pd.DataFrame(columns=columns)\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    pretrain_data, train_data, test_data, Y_train, Y_test, is_multivariate, is_instances_classification = load_data(dataset, data_type, noise_std, visualize=False)\n",
    "    for function_name in [\"ip_correct\", \"anti-oja_fast\",  \"ip-anti-oja_fast\", \"hadsp\", \"desp\"]: # \"random_ee\", \"random_ei\", \"ip_correct\", \"anti-oja\", \"anti-oja_fast\",  \"ip-anti-oja\", \"hadsp\", \"desp\"\n",
    "        # Get the best trial from the study\n",
    "        print(function_name)\n",
    "        study = retrieve_best_model(function_name, dataset, is_multivariate, variate_type = \"multi\", data_type = \"normal\")\n",
    "        \n",
    "        SRs, pearsons, CEVs, dcors = evaluate_dataset_on_test(\n",
    "            study, \n",
    "            dataset,\n",
    "            function_name, \n",
    "            pretrain_data, \n",
    "            train_data, \n",
    "            test_data,\n",
    "            Y_train, \n",
    "            Y_test,\n",
    "            is_instances_classification,\n",
    "            nb_trials = 1,\n",
    "            record_metrics=True\n",
    "        )\n",
    "        # Create a new DataFrame row\n",
    "        new_row = pd.DataFrame({\n",
    "            \"dataset\": [dataset],\n",
    "            \"function_name\": [function_name],\n",
    "            \"spectral_radius_mean\": [np.mean(SRs)],\n",
    "            \"spectral_radius_std\": [np.std(SRs)],\n",
    "            \"pearson_mean\": [np.mean(pearsons)],\n",
    "            \"pearson_std\": [np.std(pearsons)],\n",
    "            \"CEV_mean\": [np.mean(CEVs)],\n",
    "            \"CEV_std\": [np.std(CEVs)],\n",
    "            \"dcor_mean\": [np.mean(dcors)],\n",
    "            \"dcor_std\": [np.std(dcors)],\n",
    "        })\n",
    "    \n",
    "        # Concatenate the new row to the results DataFrame\n",
    "        new_results = pd.concat([new_results, new_row], ignore_index=True)\n",
    "        \n",
    "\n",
    "# Display the DataFrame\n",
    "print(new_results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc62eec2-959a-4b62-9507-9b8c5efbde0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(new_results)\n",
    "file_name = \"outputs/metrics.csv\"\n",
    "\n",
    "# Load the existing CSV\n",
    "if os.path.exists(file_name) and os.path.getsize(file_name) > 0:\n",
    "    try:\n",
    "        previous_results = pd.read_csv(file_name)\n",
    "    except pd.errors.EmptyDataError:\n",
    "        print(f\"{file_name} is empty. Initializing with default columns.\")\n",
    "        previous_results = pd.DataFrame(columns=columns)\n",
    "        previous_results.to_csv(file_name, index=False)\n",
    "else:\n",
    "    print(f\"{file_name} does not exist or is empty. Creating a new file.\")\n",
    "    previous_results = pd.DataFrame(columns=columns)\n",
    "    previous_results.to_csv(file_name, index=False)\n",
    "    \n",
    "tots_results = pd.concat([new_results, previous_results], axis=0)\n",
    "\n",
    "tots_results.to_csv(file_name, index=False)\n",
    "\n",
    "print(f\"Results saved to {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f104f22f-a28c-4f09-90f4-93d373963973",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586e4e55-cdcf-4dab-ab18-f9cf8f66d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.ticker import MaxNLocator  # Importing here for completeness\n",
    "\n",
    "# Load your data\n",
    "file_name = 'outputs/metrics.csv'\n",
    "data = pd.read_csv(file_name)\n",
    "\n",
    "datasets = [\n",
    "    \"JapaneseVowels\",\n",
    "    \"CatsDogs\",\n",
    "    \"SpokenArabicDigits\",\n",
    "    \"FSDD\",\n",
    "    \"SPEECHCOMMANDS\",\n",
    "#    \"MackeyGlass\",\n",
    "#    \"Lorenz\",\n",
    "#    \"Sunspot_daily\",\n",
    "]\n",
    "\n",
    "data = data[data[\"dataset\"].isin(datasets_keep)]\n",
    "data[\"dataset\"] = (data[\"dataset\"]\n",
    "                   .str.replace(\"SpokenArabicDigits\", \"Spoken\\nArabic\\nDigits\")\n",
    "                   .str.replace(\"SPEECHCOMMANDS\",     \"SPEECH\\nCOMMANDS\")\n",
    "                   .str.replace(\"JapaneseVowels\",     \"Japanese\\nVowels\"))\n",
    "\n",
    "data[\"Algorithm\"] = data[\"function_name\"].map(function_mapping)\n",
    "datasets       = data[\"dataset\"].unique()\n",
    "\n",
    "# Apply the mapping to create a new column with descriptive labels\n",
    "data['Algorithm'] = data['function_name'].map(function_mapping)\n",
    "\n",
    "datasets = data['dataset'].unique()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# plotting parameters\n",
    "# ------------------------------------------------------------------\n",
    "metrics       = [\"spectral_radius_mean\", \"pearson_mean\", \"CEV_mean\", \"dcor_mean\"]\n",
    "err_metrics   = [\"spectral_radius_std\",  \"pearson_std\", \"CEV_std\",  \"dcor_std\"]\n",
    "\n",
    "fontsize = 20\n",
    "width    = 0.10\n",
    "x        = np.arange(len(datasets))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# create a figure will contains only the legend and  one bar-plot figure per metric (no legends inside)\n",
    "# ------------------------------------------------------------------\n",
    "legend_fig, legend_ax = plt.subplots(figsize=(14, 2))  # very flat\n",
    "legend_ax.axis(\"off\")                                  # no axes visible\n",
    "\n",
    "for metric_index, metric in enumerate(metrics):\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # -- bars -------------------------------------------------------\n",
    "    for i, func in enumerate(functions_order):\n",
    "        subset  = data[data[\"Algorithm\"] == func]\n",
    "        means   = subset[metric].values\n",
    "        errors  = subset[err_metrics[metric_index]].values\n",
    "        ax.bar(x + i*width, means, width,\n",
    "               label=func,\n",
    "               yerr=errors, capsize=5,\n",
    "               color=function_colors[func],\n",
    "               error_kw={\"elinewidth\": 2, \"capthick\": 2})\n",
    "\n",
    "    # -- cosmetics --------------------------------------------------\n",
    "    ax.set_ylabel(metric.replace(\"_\", \" \").title(), fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"y\", labelsize=fontsize)\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=10))\n",
    "    ax.set_xticks(x + width*(len(functions_order)-1)/2)\n",
    "    ax.set_xticklabels(datasets, fontsize=fontsize)\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "    \n",
    "    fig.tight_layout()          # no extra space needed for legend\n",
    "\n",
    "    # after drawing the *first* metric, steal its handles for the legend\n",
    "    if metric_index == 0:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# --- legend -------------------------------------------------\n",
    "legend_fig.legend(handles, labels,\n",
    "                  title=\"Algorithm\",\n",
    "                  ncol=len(functions_order),\n",
    "                  loc=\"center\",            # center of this tiny figure\n",
    "                  fontsize=14, title_fontsize=14, frameon=False)\n",
    "\n",
    "legend_fig.tight_layout()\n",
    "plt.show()          # shows legend first, then the bar-plot figures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00da4ddc-eb48-49da-97bf-e9ada522fa95",
   "metadata": {},
   "source": [
    "# Separability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54929f79-bfc1-46ad-a092-7609b9964a5f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T14:34:40.607303Z",
     "start_time": "2025-04-25T14:34:40.590357Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from numpy import random\n",
    "\n",
    "# Evaluating\n",
    "from performances.esn_model_evaluation import train_model_for_classification, predict_model_for_classification, compute_score\n",
    "from performances.esn_model_evaluation import (train_model_for_prediction, init_reservoir, init_ip_reservoir, init_local_rule_reservoir, \n",
    "                                                init_ip_local_rule_reservoir, init_readout)\n",
    "from analysis.richness import spectral_radius, pearson, squared_uncoupled_dynamics_alternative, distance_correlation\n",
    "\n",
    "\n",
    "from importlib import reload\n",
    "import analysis.separability\n",
    "from analysis.separability import (\n",
    "    inter_intra_class_distance,\n",
    "    fisher_discriminant_ratio,\n",
    "    silhouette,\n",
    "    davies_bouldin,\n",
    "    calinski_harabasz\n",
    ")\n",
    "reload(analysis.separability)\n",
    "\n",
    "nb_jobs = 10\n",
    "def evaluate_dataset_on_test_alternative(study, dataset_name, function_name, pretrain_data, train_data, test_data, Y_train, Y_test, is_instances_classification, nb_trials = 8, record_metrics=False):\n",
    "    # Collect all hyperparameters in a dictionary\n",
    "    hyperparams = {param_name: param_value for param_name, param_value in study.best_trial.params.items()}\n",
    "    print(hyperparams)\n",
    "    leaky_rate = 1\n",
    "    input_connectivity = 1\n",
    "\n",
    "    # score for prediction\n",
    "    if dataset_name == \"Sunspot\":\n",
    "        start_step = 30\n",
    "        end_step = 500\n",
    "    else:\n",
    "        start_step = 500\n",
    "        end_step = 1500\n",
    "    SLICE_RANGE = slice(start_step, end_step)\n",
    "\n",
    "    if 'variance_target' not in hyperparams and 'min_variance' in hyperparams:\n",
    "        hyperparams['variance_target'] = hyperparams['min_variance']\n",
    "    if not is_instances_classification:\n",
    "        hyperparams['use_full_instance'] = False\n",
    "\n",
    "    RIDGE_COEF = 10**hyperparams['ridge']\n",
    "    \n",
    "    if function_name in [\"hadsp\", \"desp\"]:\n",
    "        max_partners = np.inf\n",
    "    \n",
    "    inter_dists = []\n",
    "    intra_dists = []\n",
    "    separability_ratios = []\n",
    "    sil_scores = []\n",
    "    dbi_scores = []\n",
    "    ch_scores  = []\n",
    "    fdr_scores = []\n",
    "\n",
    "    for i in range(nb_trials):\n",
    "        print(\"Trial\", i + 1, \"of\", nb_trials)\n",
    "        common_index = 1\n",
    "        if is_instances_classification:\n",
    "            common_size = pretrain_data[0].shape[common_index]\n",
    "        else:\n",
    "            common_size = pretrain_data.shape[common_index]\n",
    "\n",
    "        # We want the size of the reservoir to be at least network_size\n",
    "        K = math.ceil(hyperparams['network_size'] / common_size)\n",
    "        n = common_size * K\n",
    "        \n",
    "        if function_name in [\"diag_ee\", \"diag_ei\"]:\n",
    "            use_block = True\n",
    "        else:\n",
    "            use_block = False\n",
    "            \n",
    "        # UNSUPERVISED PRETRAINING \n",
    "        if function_name == \"random_ee\":\n",
    "            Win, W, bias = init_matrices(n, input_connectivity, hyperparams['connectivity'],  K, w_distribution=stats.uniform(loc=0, scale=1), use_block=use_block, seed=random.randint(0, 1000))\n",
    "        else:\n",
    "            Win, W, bias = init_matrices(n, input_connectivity, hyperparams['connectivity'],  K, w_distribution=stats.uniform(loc=-1, scale=2), use_block=use_block, seed=random.randint(0, 1000))\n",
    "        bias *= hyperparams['bias_scaling']\n",
    "        Win *= hyperparams['input_scaling']\n",
    "\n",
    "        if function_name == \"hadsp\":\n",
    "            W, (_, _, _) = run_algorithm(W, Win, bias, hyperparams['leaky_rate'], activation_function, pretrain_data, \n",
    "                                     hyperparams['weight_increment'], hyperparams['target_rate'], hyperparams['rate_spread'], function_name, \n",
    "                                     multiple_instances=is_instances_classification, \n",
    "                                     min_increment = hyperparams['min_increment'], max_increment=hyperparams['max_increment'], use_full_instance=hyperparams['use_full_instance'],\n",
    "                                     max_partners=max_partners, method=\"pearson\", n_jobs=nb_jobs)\n",
    "        elif function_name == \"desp\":\n",
    "            print(\"DESP\")\n",
    "            W, (_, _, _) = run_algorithm(W, Win, bias, hyperparams['leaky_rate'], activation_function, pretrain_data, \n",
    "                                         hyperparams['weight_increment'], hyperparams['variance_target'], hyperparams['variance_spread'], function_name, \n",
    "                                         multiple_instances=is_instances_classification, \n",
    "                                         min_increment = hyperparams['min_increment'], max_increment=hyperparams['max_increment'], use_full_instance = hyperparams['use_full_instance'], \n",
    "                                         max_partners=max_partners, method = \"pearson\", \n",
    "                                         intrinsic_saturation=hyperparams['intrinsic_saturation'], intrinsic_coef=hyperparams['intrinsic_coef'], \n",
    "                                         n_jobs = nb_jobs)\n",
    "        elif function_name in [\"random_ee\", \"random_ei\", \"diag_ee\", \"diag_ei\", \"ip_correct\", \"anti-oja_fast\", \"ip-anti-oja_fast\"]:\n",
    "            eigen = sparse.linalg.eigs(W, k=1, which=\"LM\", maxiter=W.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "            W *= hyperparams['spectral_radius'] / max(abs(eigen))\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid function: {function_name}\")\n",
    "        \n",
    "        # unsupervised local rules\n",
    "        if is_instances_classification:\n",
    "            unsupervised_pretrain = np.concatenate(pretrain_data).astype(float)\n",
    "        else:\n",
    "            unsupervised_pretrain = pretrain_data.astype(float)\n",
    "        if function_name == \"ip_correct\":\n",
    "            reservoir = init_ip_reservoir(W, Win, bias, mu=hyperparams['mu'], sigma=hyperparams['sigma'], learning_rate=hyperparams['learning_rate'],\n",
    "                                          leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function\n",
    "                                          )\n",
    "            _ = reservoir.fit(unsupervised_pretrain, warmup=100)\n",
    "        elif function_name == \"anti-oja_fast\":\n",
    "            reservoir = init_local_rule_reservoir(W, Win, bias, local_rule=\"anti-oja\", eta=hyperparams['oja_eta'],\n",
    "                                                  synapse_normalization=False, bcm_theta=None,\n",
    "                                                  leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function,\n",
    "                                                  )\n",
    "            _ = reservoir.fit(unsupervised_pretrain, warmup=100)        \n",
    "        elif function_name == \"ip-anti-oja_fast\":\n",
    "            reservoir = init_ip_local_rule_reservoir(W, Win, bias, local_rule=\"anti-oja\", eta=hyperparams['oja_eta'],\n",
    "                                                      synapse_normalization=False, bcm_theta=None,\n",
    "                                                      mu=hyperparams['mu'], sigma=hyperparams['sigma'], learning_rate=hyperparams['learning_rate'],\n",
    "                                                      leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function,\n",
    "                                                      )\n",
    "            _ = reservoir.fit(unsupervised_pretrain, warmup=100)\n",
    "        else:\n",
    "            reservoir = init_reservoir(W, Win, bias, leaky_rate, activation_function)\n",
    "        readout = init_readout(ridge_coef=RIDGE_COEF)\n",
    "\n",
    "\n",
    "        # TRAINING and EVALUATION\n",
    "        # Step 1: Collect final hidden states\n",
    "        final_states = []\n",
    "        for seq in test_data:\n",
    "            states = reservoir.run(seq)\n",
    "            final_states.append(states[-1])\n",
    "\n",
    "        final_states = np.array(final_states)  # (n_test, reservoir_dim)\n",
    "\n",
    "        # Convert one-hot labels to flat labels\n",
    "        if Y_test.ndim == 2:\n",
    "            y_test = np.argmax(Y_test, axis=1)\n",
    "        else:\n",
    "            y_test = np.array(Y_test)\n",
    "\n",
    "        # Step 2: Compute inter/intra class distances\n",
    "        if is_instances_classification:\n",
    "            inter_dist, intra_dist, sep_ratio = inter_intra_class_distance(final_states, y_test)\n",
    "            sil = silhouette(final_states, y_test)\n",
    "            dbi = davies_bouldin(final_states, y_test)\n",
    "            ch  = calinski_harabasz(final_states, y_test)\n",
    "            fdr = fisher_discriminant_ratio(final_states, y_test)\n",
    "\n",
    "            inter_dists.append(inter_dist)\n",
    "            intra_dists.append(intra_dist)\n",
    "            separability_ratios.append(sep_ratio)\n",
    "\n",
    "            sil_scores.append(sil)\n",
    "            dbi_scores.append(dbi)\n",
    "            ch_scores.append(ch)\n",
    "            fdr_scores.append(fdr)\n",
    "\n",
    "    return {\n",
    "        'inter': inter_dists,\n",
    "        'intra': intra_dists,\n",
    "        'ratio': separability_ratios,\n",
    "        'silhouette': sil_scores,\n",
    "        'davies_bouldin': dbi_scores,\n",
    "        'calinski_harabasz': ch_scores,\n",
    "        'fisher_ratio': fdr_scores\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79a119ad50576960",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-25T16:25:42.906788Z",
     "start_time": "2025-04-25T14:34:43.339261Z"
    }
   },
   "outputs": [],
   "source": [
    "from performances.utility import retrieve_best_model\n",
    "\n",
    "datasets = [\n",
    "    \"JapaneseVowels\",\n",
    "    \"CatsDogs\",\n",
    "    \"FSDD\",\n",
    "    \"SpokenArabicDigits\",\n",
    "    # \"SPEECHCOMMANDS\",\n",
    "]\n",
    "\n",
    "\n",
    "corr_columns = []\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    pretrain_data, train_data, test_data, Y_train, Y_test, is_multivariate, \\\n",
    "        is_instances_classification = load_data(dataset, data_type, noise_std, visualize=False)\n",
    "\n",
    "    for function_name in [\n",
    "        \"random_ee\", \"random_ei\", \"ip_correct\",\n",
    "        \"anti-oja_fast\", \"ip-anti-oja_fast\", \"hadsp\", \"desp\",\n",
    "    ]:\n",
    "        print(function_name)\n",
    "\n",
    "        study = retrieve_best_model(\n",
    "            function_name, dataset, is_multivariate,\n",
    "            variate_type=\"multi\", data_type=\"normal\"\n",
    "        )\n",
    "\n",
    "        results = evaluate_dataset_on_test_alternative(\n",
    "            study, dataset, function_name,\n",
    "            pretrain_data, train_data, test_data,\n",
    "            Y_train, Y_test,\n",
    "            is_instances_classification,\n",
    "            nb_trials=4,\n",
    "            record_metrics=True\n",
    "        )\n",
    "\n",
    "        # add *one* dict to corr_rows\n",
    "        corr_columns.append({\n",
    "            \"dataset\": dataset,\n",
    "            \"function_name\": function_name,\n",
    "            \"inter_dists_mean\": np.mean(results['inter']),\n",
    "            \"inter_dists_std\":  np.std(results['inter']),\n",
    "            \"intra_dists_mean\": np.mean(results['intra']),\n",
    "            \"intra_dists_std\":  np.std(results['intra']),\n",
    "            \"separability_ratios_mean\": np.mean(results['ratio']),\n",
    "            \"separability_ratios_std\":  np.std(results['ratio']),\n",
    "            \"silhouette_mean\": np.mean(results['silhouette']),\n",
    "            \"silhouette_std\":  np.std(results['silhouette']),\n",
    "            \"davies_bouldin_mean\": np.mean(results['davies_bouldin']),\n",
    "            \"davies_bouldin_std\":  np.std(results['davies_bouldin']),\n",
    "            \"calinski_harabasz_mean\": np.mean(results['calinski_harabasz']),\n",
    "            \"calinski_harabasz_std\":  np.std(results['calinski_harabasz']),\n",
    "            \"fisher_ratio_mean\": np.mean(results['fisher_ratio']),\n",
    "            \"fisher_ratio_std\":  np.std(results['fisher_ratio']),\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d43d452cab13b98a",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = \"outputs/metrics.csv\"\n",
    "\n",
    "orig    = pd.read_csv(file_name).set_index([\"dataset\", \"function_name\"])\n",
    "corr_df = pd.DataFrame(corr_columns).set_index([\"dataset\", \"function_name\"])\n",
    "\n",
    "# 1) make sure orig has all the columns corr_df has (fills with NaN where missing)\n",
    "for col in corr_df.columns:\n",
    "    if col not in orig.columns:\n",
    "        orig[col] = np.nan\n",
    "\n",
    "# 2) now update in-place (only non-null values from corr_df overwrite orig)\n",
    "orig.update(corr_df)\n",
    "\n",
    "# 3) reset index & write out\n",
    "augmented = orig.reset_index()\n",
    "augmented.to_csv(file_name, index=False)\n",
    "print(f\"✔ Added / updated columns in {file_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11ff25c-19a7-401c-83c9-1106c8de7b13",
   "metadata": {},
   "source": [
    "## Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c654152b0088398c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# read & prepare the data  \n",
    "# ------------------------------------------------------------------\n",
    "data = pd.read_csv(\"outputs/metrics.csv\")\n",
    "\n",
    "datasets = [\n",
    "    \"JapaneseVowels\", \"CatsDogs\", \"SpokenArabicDigits\",\n",
    "    \"FSDD\", \"SPEECHCOMMANDS\"\n",
    "]\n",
    "\n",
    "data = data[data[\"dataset\"].isin(datasets)]\n",
    "data[\"dataset\"] = (data[\"dataset\"]\n",
    "                   .str.replace(\"SpokenArabicDigits\", \"Spoken\\nArabic\\nDigits\")\n",
    "                   .str.replace(\"SPEECHCOMMANDS\",     \"SPEECH\\nCOMMANDS\")\n",
    "                   .str.replace(\"JapaneseVowels\",     \"Japanese\\nVowels\"))\n",
    "\n",
    "# … your mapping / palette …\n",
    "data[\"Algorithm\"] = data[\"function_name\"].map(function_mapping)\n",
    "datasets = data[\"dataset\"].unique()\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# parameters\n",
    "# ------------------------------------------------------------------\n",
    "metrics       = [\"inter_dists_mean\",  \"intra_dists_mean\",\n",
    "                 \"separability_ratios_mean\", \"silhouette_mean\",\n",
    "                 \"davies_bouldin_mean\", \"calinski_harabasz_mean\",\n",
    "                 \"fisher_ratio_mean\"]\n",
    "\n",
    "error_metrics = [\"inter_dists_std\",  \"intra_dists_std\",\n",
    "                 \"separability_ratios_std\", \"silhouette_std\",\n",
    "                 \"davies_bouldin_std\", \"calinski_harabasz_std\",\n",
    "                 \"fisher_ratio_std\"]\n",
    "\n",
    "fontsize = 20\n",
    "width    = 0.10\n",
    "x        = np.arange(len(datasets))\n",
    "\n",
    "# ------------------------------------------------------------------\n",
    "# create a legend figure and  bar-plot figures\n",
    "# ------------------------------------------------------------------\n",
    "legend_fig, legend_ax = plt.subplots(figsize=(14, 2))   # flat banner\n",
    "legend_ax.axis(\"off\")                                   # hide axes\n",
    "handles = labels = None   # will be filled when we plot the first metric\n",
    "\n",
    "\n",
    "for m, metric in enumerate(metrics):\n",
    "    fig, ax = plt.subplots(figsize=(14, 8))\n",
    "\n",
    "    # --- bars ------------------------------------------------------\n",
    "    for i, func in enumerate(functions_order):\n",
    "        subset  = data[data[\"Algorithm\"] == func]\n",
    "        means   = subset[metric].values\n",
    "        errors  = subset[error_metrics[m]].values\n",
    "\n",
    "        ax.bar(x + i*width, means, width,\n",
    "               label=func,\n",
    "               yerr=errors, capsize=5,\n",
    "               color=function_colors[func],\n",
    "               error_kw={\"elinewidth\": 2, \"capthick\": 2})\n",
    "\n",
    "    # --- cosmetics -------------------------------------------------\n",
    "    ax.set_ylabel(metric.replace(\"_\", \" \").title(), fontsize=fontsize)\n",
    "    ax.tick_params(axis=\"y\", labelsize=fontsize)\n",
    "    ax.yaxis.set_major_locator(MaxNLocator(nbins=10))\n",
    "    ax.set_xticks(x + width*(len(functions_order)-1)/2)\n",
    "    ax.set_xticklabels(datasets, fontsize=fontsize)\n",
    "\n",
    "    # remove top/right spines\n",
    "    ax.spines[\"top\"].set_visible(False)\n",
    "    ax.spines[\"right\"].set_visible(False)\n",
    "\n",
    "    # grab legend entries once (from the first metric figure)\n",
    "    if m == 0:\n",
    "        handles, labels = ax.get_legend_handles_labels()\n",
    "\n",
    "# --- legend -------------------------------------------------\n",
    "legend_fig.legend(handles, labels,\n",
    "                  title=\"Algorithm\",\n",
    "                  ncol=len(functions_order),\n",
    "                  loc=\"center\",\n",
    "                  fontsize=14, title_fontsize=14, frameon=False)\n",
    "\n",
    "legend_fig.tight_layout()\n",
    "plt.show()                      # shows the legend banner"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f86a468b-42a9-4c8e-ae77-cc0ebfaba1ae",
   "metadata": {},
   "source": [
    "# Final matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7ce7dd-4826-4a68-ab44-66ef90f031de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from performances.utility import camel_to_snake, retrieve_best_model\n",
    "from reservoir.reservoir import init_matrices\n",
    "from connexion_generation.hag import run_algorithm\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "# List of datasets\n",
    "classification = [\n",
    "    \"JapaneseVowels\",\n",
    "    \"CatsDogs\",\n",
    "    \"FSDD\",\n",
    "    \"SpokenArabicDigits\",\n",
    "    \"SPEECHCOMMANDS\",\n",
    "]\n",
    "\n",
    "prediction = [\n",
    "    \"MackeyGlass\",\n",
    "    \"Lorenz\",\n",
    "    \"Sunspot_daily\",\n",
    "]\n",
    "datasets=prediction\n",
    "\n",
    "\n",
    "# Initialize lists to store results and max values\n",
    "Ws = []\n",
    "titles = []\n",
    "max_values = []\n",
    "\n",
    "leaky_rate = 1\n",
    "input_connectivity = 1\n",
    "\n",
    "# Loop through datasets and function names to compute W matrices and find global vmax\n",
    "for dataset in datasets:\n",
    "    print(dataset)\n",
    "    pretrain_data, train_data, test_data, Y_train, Y_test, is_multivariate, is_instances_classification = load_data(dataset, data_type, noise_std)\n",
    "\n",
    "    for function_name in [\"random_ee\", \"random_ei\", \"diag_ee\", \"diag_ei\", \"ip_correct\", \"anti-oja_fast\", \"ip-anti-oja_fast\",  \"hadsp\", \"desp\"]:\n",
    "        print(function_name)\n",
    "        # Get the best trial from the study\n",
    "        study = retrieve_best_model(function_name, dataset, is_multivariate, variate_type = \"multi\", data_type = \"normal\")\n",
    "        hyperparams = {param_name: param_value for param_name, param_value in study.best_trial.params.items()}\n",
    "        print(hyperparams)\n",
    "\n",
    "        if 'variance_target' not in hyperparams and 'min_variance' in hyperparams:\n",
    "            hyperparams['variance_target'] = hyperparams['min_variance']\n",
    "        if not is_instances_classification:\n",
    "            hyperparams['use_full_instance'] = False\n",
    "    \n",
    "        if function_name in [\"hadsp\", \"desp\"]:\n",
    "            max_partners = np.inf\n",
    "        \n",
    "        common_index = 1\n",
    "        if is_instances_classification:\n",
    "            common_size = pretrain_data[0].shape[common_index]\n",
    "        else:\n",
    "            common_size = pretrain_data.shape[common_index]\n",
    "\n",
    "        # We want the size of the reservoir to be at least network_size\n",
    "        K = math.ceil(hyperparams[\"network_size\"] / common_size)\n",
    "        n = common_size * K\n",
    "        \n",
    "        if function_name in [\"diag_ee\", \"diag_ei\"]:\n",
    "            use_block = True\n",
    "        else:\n",
    "            use_block = False\n",
    "            \n",
    "        # UNSUPERVISED PRETRAINING \n",
    "        if function_name == \"random_ee\":\n",
    "            Win, W, bias = init_matrices(n, input_connectivity, hyperparams['connectivity'],  K, w_distribution=stats.uniform(loc=0, scale=1), use_block=use_block, seed=random.randint(0, 1000))\n",
    "        else:\n",
    "            Win, W, bias = init_matrices(n, input_connectivity, hyperparams['connectivity'],  K, w_distribution=stats.uniform(loc=-1, scale=2), use_block=use_block, seed=random.randint(0, 1000))\n",
    "        bias *= hyperparams['bias_scaling']\n",
    "        Win *= hyperparams['input_scaling']\n",
    "\n",
    "        if function_name == \"hadsp\":\n",
    "            W, (_, _, _) = run_algorithm(W, Win, bias, hyperparams['leaky_rate'], activation_function, pretrain_data, \n",
    "                                     hyperparams['weight_increment'], hyperparams['target_rate'], hyperparams['rate_spread'], function_name, \n",
    "                                     multiple_instances=is_instances_classification, \n",
    "                                     min_increment = hyperparams['min_increment'], max_increment=hyperparams['max_increment'], use_full_instance=hyperparams['use_full_instance'],\n",
    "                                     max_partners=max_partners, method=\"pearson\", n_jobs=nb_jobs)\n",
    "        elif function_name == \"desp\":\n",
    "            W, (_, _, _) = run_algorithm(W, Win, bias, hyperparams['leaky_rate'], activation_function, pretrain_data, \n",
    "                                         hyperparams['weight_increment'], hyperparams['variance_target'], hyperparams['variance_spread'], function_name, \n",
    "                                         multiple_instances=is_instances_classification, \n",
    "                                         min_increment = hyperparams['min_increment'], max_increment=hyperparams['max_increment'], use_full_instance = hyperparams['use_full_instance'], \n",
    "                                         max_partners=max_partners, method = \"pearson\", \n",
    "                                         intrinsic_saturation=hyperparams['intrinsic_saturation'], intrinsic_coef=hyperparams['intrinsic_coef'], \n",
    "                                         n_jobs = nb_jobs)\n",
    "        elif function_name in [\"random_ee\", \"random_ei\"]:\n",
    "            eigen = sparse.linalg.eigs(W, k=1, which=\"LM\", maxiter=W.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "            W *= hyperparams['spectral_radius'] / max(abs(eigen))\n",
    "            \n",
    "        elif function_name in [\"ip_correct\", \"anti-oja_fast\", \"ip-anti-oja_fast\"]:\n",
    "            eigen = sparse.linalg.eigs(W, k=1, which=\"LM\", maxiter=W.shape[0] * 20, tol=0.1, return_eigenvectors=False)\n",
    "            W *= hyperparams['spectral_radius'] / max(abs(eigen))\n",
    "\n",
    "            # unsupervised local rules\n",
    "            if is_instances_classification:\n",
    "                unsupervised_pretrain = np.concatenate(pretrain_data).astype(float)\n",
    "            else:\n",
    "                unsupervised_pretrain = pretrain_data.astype(float)\n",
    "            if function_name == \"ip_correct\":\n",
    "                reservoir = init_ip_reservoir(W, Win, bias, mu=hyperparams['mu'], sigma=hyperparams['sigma'], learning_rate=hyperparams['learning_rate'],\n",
    "                                              leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function\n",
    "                                              )\n",
    "                _ = reservoir.fit(unsupervised_pretrain, warmup=100)\n",
    "            elif function_name == \"anti-oja_fast\":\n",
    "                reservoir = init_local_rule_reservoir(W, Win, bias, local_rule=\"anti-oja\", eta=hyperparams['oja_eta'],\n",
    "                                                       synapse_normalization=True, bcm_theta=None,\n",
    "                                                       leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function,\n",
    "                                                       )\n",
    "                _ = reservoir.fit(unsupervised_pretrain, warmup=100)\n",
    "            elif function_name == \"ip-anti-oja_fast\":\n",
    "                reservoir = init_ip_local_rule_reservoir(W, Win, bias, local_rule=\"anti-oja\", eta=hyperparams['oja_eta'],\n",
    "                                                          synapse_normalization=True, bcm_theta=None,\n",
    "                                                          mu=hyperparams['mu'], sigma=hyperparams['sigma'], learning_rate=hyperparams['learning_rate'],\n",
    "                                                          leaking_rate=hyperparams['leaky_rate'], activation_function=activation_function,\n",
    "                                                          )\n",
    "                _ = reservoir.fit(unsupervised_pretrain, warmup=100)\n",
    "            else:\n",
    "                reservoir = init_reservoir(W, Win, bias, leaky_rate, activation_function)\n",
    "\n",
    "            W = reservoir.W\n",
    "            \n",
    "\n",
    "        # Store W matrix and corresponding title\n",
    "        Ws.append(W)\n",
    "        titles.append(f\"{dataset} - {[function_name]}\")\n",
    "        max_values.append(np.max(W))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ccacef-d0d2-4633-9c30-a226789aa15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import numpy as np\n",
    "\n",
    "n_datasets = len(datasets)\n",
    "n_functions = len(functions_order)\n",
    "\n",
    "# 1) Determine global min/max to center color scale around 0\n",
    "# Flatten all Ws into one array to find overall min & max\n",
    "all_values = []\n",
    "for W in Ws:\n",
    "    if hasattr(W, \"toarray\"):\n",
    "        W = W.toarray()\n",
    "    all_values.append(W.ravel())\n",
    "all_values = np.concatenate(all_values)\n",
    "\n",
    "global_abs_max = np.max(np.abs(all_values))  # largest absolute value\n",
    "g_vmin, g_vmax = -global_abs_max, global_abs_max\n",
    "\n",
    "# 2) Create a figure with one row per dataset and one column per function\n",
    "fig, axes = plt.subplots(\n",
    "    n_datasets, \n",
    "    n_functions, \n",
    "    figsize=(n_functions * 3, n_datasets * 3),\n",
    "    sharex=True, \n",
    "    sharey=True\n",
    ")\n",
    "\n",
    "# Ensure axes is 2D even if n_datasets=1 or n_functions=1\n",
    "if n_datasets == 1:\n",
    "    axes = np.array([axes])\n",
    "if n_functions == 1:\n",
    "    axes = np.array([axes]).T\n",
    "\n",
    "idx = 0\n",
    "im = None  # to store the last image for the colorbar\n",
    "for i in range(n_datasets):\n",
    "    for j in range(n_functions):\n",
    "        W = Ws[idx]\n",
    "        idx += 1\n",
    "        \n",
    "        # Convert to dense if sparse\n",
    "        if hasattr(W, \"toarray\"):\n",
    "            W = W.toarray()\n",
    "        \n",
    "        # 3) Plot base heatmap, using a diverging colormap like 'bwr'\n",
    "        #    and a symmetric vmin/vmax around 0\n",
    "        local_abs_max = np.max(np.abs(W))\n",
    "        vmin, vmax = -local_abs_max, local_abs_max\n",
    "        \n",
    "        im = axes[i, j].imshow(\n",
    "            W, \n",
    "            cmap='seismic', \n",
    "            interpolation='nearest', \n",
    "            vmin=vmin, \n",
    "            vmax=vmax\n",
    "        )\n",
    "        \n",
    "        # 4) Overlay zeros in white\n",
    "        zero_mask = (W == 0)\n",
    "        axes[i, j].imshow(\n",
    "            np.ma.masked_where(~zero_mask, W),\n",
    "            cmap=mcolors.ListedColormap(['white']),\n",
    "            interpolation='nearest'\n",
    "        )\n",
    "        \n",
    "        # Remove per-subplot x/y labels\n",
    "        axes[i, j].set_xlabel('')\n",
    "        axes[i, j].set_ylabel('')\n",
    "        \n",
    "        # Row label: dataset name on the left edge\n",
    "        if j == 0:\n",
    "            axes[i, j].text(\n",
    "                -0.3, 0.5, datasets[i],\n",
    "                rotation=90,\n",
    "                transform=axes[i, j].transAxes,\n",
    "                ha='center',\n",
    "                va='center',\n",
    "                fontsize=12\n",
    "            )\n",
    "        \n",
    "        # Column label: function name on top row\n",
    "        if i == 0:\n",
    "            axes[i, j].set_title(functions_order[j], fontsize=12)\n",
    "            \n",
    "        # 5) Add a colorbar for each heatmap\n",
    "        #cbar = fig.colorbar(im, ax=axes[i, j], fraction=0.046, pad=0.04)\n",
    "        #cbar.ax.tick_params(labelsize=10)\n",
    "        \n",
    "# 5) Add shared axis labels\n",
    "fig.text(0.5, 0.04, 'Neurons', ha='center', va='center', fontsize=14)\n",
    "fig.text(0.04, 0.5, 'Neurons', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "\n",
    "# Tight layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Single colorbar on the right\n",
    "cbar = fig.colorbar(im, ax=axes.ravel().tolist(), fraction=0.03, pad=0.04)\n",
    "cbar.set_label('Value', fontsize=12)\n",
    "plt.savefig(f'connectivity_matrices.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d505632-3b59-41d6-9aa5-18dd42c8a5ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821d76b8-70f0-4152-80d7-c95dd62e1ad5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hag_env",
   "language": "python",
   "name": "hag_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
